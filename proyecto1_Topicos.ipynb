{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "executionInfo": {
     "elapsed": 1740,
     "status": "error",
     "timestamp": 1678328741345,
     "user": {
      "displayName": "Alexander Luna",
      "userId": "00007086188915596657"
     },
     "user_tz": 300
    },
    "id": "hQIxkt79dH4Y",
    "outputId": "4be02022-b2f4-4167-c6ed-05d9de3cbef1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import os\n",
    "import requests\n",
    "import pandas_profiling\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import tensorflow as tf\n",
    "import tfx\n",
    "from tfx.components import CsvExampleGen\n",
    "from tfx.components import ExampleValidator\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.v1.components import ImportSchemaGen\n",
    "from tfx.components import StatisticsGen\n",
    "from tfx.components import Transform\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "from tfx.dsl.components.common.importer import Importer\n",
    "import tensorflow_data_validation as tfdv\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Conexion y carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xBuB0IcczOs"
   },
   "outputs": [],
   "source": [
    "# Ubicación pipeline\n",
    "_pipeline_root = './pipeline/'\n",
    "\n",
    "# Ubicación data en bruto\n",
    "_data_root = './data/covertype'\n",
    "\n",
    "# Ruta entrenamiento\n",
    "_data_filepath = os.path.join(_data_root, 'covertype_train.csv')\n",
    "\n",
    "# Descarga de datos\n",
    "os.makedirs(_data_root, exist_ok=True)\n",
    "if not os.path.isfile(_data_filepath):\n",
    "  url = 'https://docs.google.com/uc?export= \\\n",
    "  download&confirm={{VALUE}}&id=1lVF1BCWLH4eXXV_YOJzjR7xZjj-wAGj9'\n",
    "  r = requests.get(url, allow_redirects=True, stream=True)\n",
    "  open(_data_filepath, 'wb').write(r.content) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Exploración conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FTQUNNr4j8j"
   },
   "outputs": [],
   "source": [
    "# se crea un dataframe con la data de entrenamiento para su manipulación\n",
    "df = pd.DataFrame(pd.read_csv('data/covertype//covertype_train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1678251944546,
     "user": {
      "displayName": "Alexander Luna",
      "userId": "00007086188915596657"
     },
     "user_tz": 300
    },
    "id": "6I09gull7ZJV",
    "outputId": "267443e8-666e-445c-8d7e-fad876cda6e3"
   },
   "outputs": [],
   "source": [
    "# obtener la forma (número de filas y columnas)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1678251946332,
     "user": {
      "displayName": "Alexander Luna",
      "userId": "00007086188915596657"
     },
     "user_tz": 300
    },
    "id": "RK6zYP3f7tLE",
    "outputId": "354644b1-e190-4a05-9b0d-dc31d292c379"
   },
   "outputs": [],
   "source": [
    "# obtener la lista de columnas\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 153,
     "status": "ok",
     "timestamp": 1678251948083,
     "user": {
      "displayName": "Alexander Luna",
      "userId": "00007086188915596657"
     },
     "user_tz": 300
    },
    "id": "-FZ-JGxT7v7t",
    "outputId": "3b83042a-f29e-4d34-cb78-ec0f11ffe16b"
   },
   "outputs": [],
   "source": [
    "# mostrar información sobre el DataFrame\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 201,
     "status": "ok",
     "timestamp": 1678251950199,
     "user": {
      "displayName": "Alexander Luna",
      "userId": "00007086188915596657"
     },
     "user_tz": 300
    },
    "id": "YZz-ZSF47yaO",
    "outputId": "54251520-4d6d-42d2-ad5e-ce71e798bea2"
   },
   "outputs": [],
   "source": [
    "# mostrar estadísticas descriptivas\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Seleccion de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8jFq1acGA-h"
   },
   "outputs": [],
   "source": [
    "#Selección de las variables numericas\n",
    "num = df.select_dtypes(include = 'number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6548AdOlLcsQ"
   },
   "source": [
    "Seleccion de subconjunto que tenga un gran valor predictivo para la etiqueta 'Cover Type':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHp3n-NkKFiE"
   },
   "outputs": [],
   "source": [
    "# Extracción de todas las filas y todas las columnas de la variable num, excepto la última columna.\n",
    "# features_num es un DataFrame que contiene solo las características numéricas del conjunto de datos original,\n",
    "# sin la variable objetivo.\n",
    "\n",
    "features_num = num.iloc[:, 0:-1] \n",
    "\n",
    "#Extracción de la columna \"Cover_Type\" del DataFrame num para asignarla a la variable label_num.\n",
    "#Se crea una serie que contiene los valores de la variable objetivo para el conjunto de datos original.\n",
    "\n",
    "label_num = num['Cover_Type'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ASXX6_DKNUL"
   },
   "outputs": [],
   "source": [
    "# Se crea un objeto SelectKBest que se utiliza para realizar la selección de características univariante.\n",
    "# El parámetro score_func especifica la función de puntuación que se utilizará para evaluar la importancia\n",
    "# de cada característica individual.\n",
    "\n",
    "#En este caso, se están seleccionando las 8 características con la puntuación más alta según la función \n",
    "#f_classif.\n",
    "\n",
    "select = SelectKBest(score_func=f_classif,k = 8)\n",
    "# El método fit_transform se utiliza para ajustar el objeto SelectKBest a las características de \n",
    "# entrada features_num y la variable objetivo label_num, \n",
    "# y para transformar las características originales en un nuevo conjunto de datos que contiene solo \n",
    "# las características seleccionadas.\n",
    "z = select.fit_transform(features_num,label_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1678251958663,
     "user": {
      "displayName": "Alexander Luna",
      "userId": "00007086188915596657"
     },
     "user_tz": 300
    },
    "id": "Rg6hGpVwKkjj",
    "outputId": "82ded212-be50-46cc-e4f2-ef2d0f763382"
   },
   "outputs": [],
   "source": [
    "# Se obtiene una lista de booleanos que indican si cada característica en features_num ha sido\n",
    "# seleccionada o no por el objeto SelectKBest.\n",
    "\n",
    "filter = list(select.get_support())\n",
    "filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1678251960564,
     "user": {
      "displayName": "Alexander Luna",
      "userId": "00007086188915596657"
     },
     "user_tz": 300
    },
    "id": "bq1BljYSKr5b",
    "outputId": "addc3c8d-9395-4b0e-8191-8fbf8ed43d85"
   },
   "outputs": [],
   "source": [
    "# feature_names contiene la lista de nombres de características, que se utiliza para etiquetar \n",
    "# las características en los resultados de la selección de características.\n",
    "\n",
    "feature_names = list(features_num.columns)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 146,
     "status": "ok",
     "timestamp": 1678251964094,
     "user": {
      "displayName": "Alexander Luna",
      "userId": "00007086188915596657"
     },
     "user_tz": 300
    },
    "id": "PRrMtTjiKzVT",
    "outputId": "15f88aaf-3fb8-4faa-aefb-0e64f07856e3"
   },
   "outputs": [],
   "source": [
    "# Crea un objeto DataFrame de pandas que contiene los nombres de las características seleccionadas \n",
    "# después de la selección de características univariada.\n",
    "numss = pd.DataFrame(feature_names,filter)\n",
    "numss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez se han identificado las 2 columnas numericas con menor relevancia, se proceda a \n",
    "# eliminarlas del dataset original\n",
    "\n",
    "df_2 = df.drop(['Hillshade_3pm','Aspect'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define el nombre del archivo que se guardará como csv\n",
    "outname = 'subconjunto_train.csv'\n",
    "\n",
    "# se crea una ruta para almacenar el csv producto de la eliminación de las columnas menos relevantes\n",
    "_subconjunto_data_root = './data/covertype/subconjunto'\n",
    "\n",
    "# se crea el directorio donde se almacenará el csv\n",
    "if not os.path.exists(_subconjunto_data_root):\n",
    "    os.mkdir(_subconjunto_data_root)\n",
    "\n",
    "fullname = os.path.join(_subconjunto_data_root, outname)    \n",
    "\n",
    "df.to_csv(fullname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Configurar el contexto interactivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se inicializa contexto interactivo\n",
    "context = InteractiveContext(pipeline_root=_pipeline_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1srXErZ3bacQ"
   },
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Generando Ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbFp-S45bgwo"
   },
   "outputs": [],
   "source": [
    "# Se crea un componente de generación de ejemplos (example gen) utilizando la clase CsvExampleGen de TFX\n",
    "# El componente se configura para leer los datos de los archivos CSV en la carpeta especificada en _subconjunto_data_root.\n",
    "\n",
    "example_gen = CsvExampleGen(input_base=_subconjunto_data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KBPVXZ7bikY"
   },
   "outputs": [],
   "source": [
    "# Se ejecuta el componente example_gen dentro del contexto interactivo de TFX especificado en la variable context.\n",
    "# La ejecución del componente example_gen lee los datos de los archivos CSV especificados en el argumento \n",
    "# input_base del objeto CsvExampleGen creado anteriormente, y los convierte en ejemplos para entrenar el modelo.\n",
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obriene el artefacto\n",
    "artifact = example_gen.outputs['examples'].get()[0]\n",
    "\n",
    "# se imprimen los split names & uri\n",
    "print(f'split names: {artifact.split_names}')\n",
    "print(f'artifact uri: {artifact.uri}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtiene el URI del artefacto de salida que representa los ejemplos de entrenamiento\n",
    "train_uri = os.path.join(artifact.uri, 'Split-train')\n",
    "\n",
    "# se consulta el contenido de la carpeta train\n",
    "!ls {train_uri}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se obtiene la lista de archivos de este directorio (todos los archivos TFRecord comprimidos)\n",
    "tfrecord_filenames = [os.path.join(train_uri, name)\n",
    "                      for name in os.listdir(train_uri)]\n",
    "\n",
    "# Se crea `TFRecordDataset` para leer estos archivos\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define una función para obtener ejemplos individuales en tfrecord\n",
    "def get_records(dataset, num_records):\n",
    "\n",
    "    records = []\n",
    "    for tfrecord in dataset.take(num_records):\n",
    "        serialized_example = tfrecord.numpy()\n",
    "        \n",
    "        example = tf.train.Example()\n",
    "        \n",
    "        example.ParseFromString(serialized_example)\n",
    "        \n",
    "        example_dict = (MessageToDict(example))\n",
    "        \n",
    "        records.append(example_dict)\n",
    "        \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtienen los primeros 5 ejemplos para entrenamiento\n",
    "sample_records = get_records(dataset, 5)\n",
    "pp.pprint(sample_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Estadísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate StatisticsGen with the ExampleGen ingested dataset\n",
    "statistics_gen = StatisticsGen(\n",
    "    examples=example_gen.outputs['examples'])\n",
    "\n",
    "# Execute the component\n",
    "context.run(statistics_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the output statistics\n",
    "context.show(statistics_gen.outputs['statistics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Inferir el esquema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate SchemaGen with the StatisticsGen ingested dataset\n",
    "schema_gen = SchemaGen(statistics=statistics_gen.outputs['statistics'],    )\n",
    "\n",
    "# Run the component\n",
    "context.run(schema_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se visualiza el esquema\n",
    "context.show(schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Curando el esquema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se guarda el esquema creado en 4.4\n",
    "## codigo de referencia tomado de: https://notebook.community/GoogleCloudPlatform/mlops-on-gcp/workshops/tfx-caip-tf21/lab-01-tfx-walkthrough/lab-01\n",
    "\n",
    "schema_proto_path = '{}/{}'.format(schema_gen.outputs['schema'].get()[0].uri, 'schema.pbtxt')\n",
    "schema = tfdv.load_schema_text(schema_proto_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se ajusta el dominio para las variables mostradas\n",
    "tfdv.set_domain(schema, 'Hillshade_9am', tfdv.utils.schema_util.schema_pb2.IntDomain(min=0, max=255))\n",
    "tfdv.set_domain(schema, 'Hillshade_Noon', tfdv.utils.schema_util.schema_pb2.IntDomain(min=0, max=255))\n",
    "tfdv.set_domain(schema, 'Slope', tfdv.utils.schema_util.schema_pb2.IntDomain(min=0, max=90))\n",
    "tfdv.set_domain(schema, 'Cover_Type', tfdv.utils.schema_util.schema_pb2.IntDomain(min=0, max=6,is_categorical=True))\n",
    "\n",
    "tfdv.display_schema(schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guarda y actualiza el esquema\n",
    "# ref codigo: https://notebook.community/GoogleCloudPlatform/mlops-on-gcp/workshops/tfx-caip-tf21/lab-01-tfx-walkthrough/lab-01\n",
    "schema_dir = os.path.join(schema_gen.outputs['schema'].get()[0].uri, 'schema')\n",
    "tf.io.gfile.makedirs(schema_gen.outputs['schema'].get()[0].uri)\n",
    "schema_file = os.path.join(schema_gen.outputs['schema'].get()[0].uri, 'schema.pbtxt')\n",
    "\n",
    "tfdv.write_schema_text(schema, schema_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {schema_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se importa el esquema actualizado \n",
    "schema_importer = Importer(\n",
    "    source_uri=schema_gen.outputs['schema'].get()[0].uri,\n",
    "    artifact_type = tfx.types.standard_artifacts.Schema,\n",
    "    reimport=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se ejecuta el nuevo esquema\n",
    "context.run(schema_importer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se verifica que el esquema contiene los cambios en el domminio\n",
    "context.show(schema_importer.outputs['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6  Entornos de esquema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se recrean los datos de entrada \n",
    "servicio = df_2.drop(['Cover_Type'], axis = 1)\n",
    "servicio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define el nombre del archivo que se guardará como csv\n",
    "outname = 'servicio_train.csv'\n",
    "\n",
    "# se crea una ruta para almacenar el csv producto de la eliminación de las columnas menos relevantes\n",
    "_servicio_data_root = './data/covertype/subconjunto/servicio'\n",
    "\n",
    "# se crea el directorio donde se almacenará el csv\n",
    "if not os.path.exists(_servicio_data_root):\n",
    "    os.mkdir(_servicio_data_root)\n",
    "\n",
    "fullname = os.path.join(_servicio_data_root, outname)    \n",
    "\n",
    "df.to_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se define la ruta del archivo de servicio\n",
    "archivo_servicio = fullname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se generan estadisticas a partir del archivo de servicio\n",
    "estadisticas_de_servicio = tfdv.generate_statistics_from_csv(archivo_servicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# se validan las anomalias en el archivo de servicio, teniendo como referencia el esquema inicial\n",
    "anomalias_en_servicio = tfdv.validate_statistics(estadisticas_de_servicio, schema)\n",
    "tfdv.display_anomalies(anomalias_en_servicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### deberia aparcer como anomalia que no encuentra a columna de cover_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.display_schema(schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7. Genere nuevas estad´ısticas usando el esquema actualizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_scheme = ImportSchemaGen(schema_file= schema_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(updated_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se generan estadisticas basadas en el esquema actualizado\n",
    "updated_statistics = StatisticsGen(examples = example_gen.outputs['examples'],schema=updated_scheme.outputs['schema'])\n",
    "context.run(updated_statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se visualizan las estadisticas\n",
    "context.show(updated_statistics.outputs['statistics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8. Comprobar anomalías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_validator = ExampleValidator(\n",
    "    statistics = updated_statistics.outputs['statistics'],\n",
    "    schema = updated_scheme.outputs['schema'])\n",
    "\n",
    "context.run(example_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se valida si existe alguna anomalia con el esquema y estadisticas actualizadas\n",
    "context.show(example_validator.outputs['anomalies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4.9. Ingeniería de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.10 Función de preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.11 Transformar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Metadatos de aprendizaje automático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "def get_records(dataset, num_records):\n",
    "    '''Extracts records from the given dataset.\n",
    "    Args:\n",
    "        dataset (TFRecordDataset): dataset saved by ExampleGen\n",
    "        num_records (int): number of records to preview\n",
    "    '''\n",
    "    \n",
    "    # initialize an empty list\n",
    "    records = []\n",
    "    \n",
    "    # Use the `take()` method to specify how many records to get\n",
    "    for tfrecord in dataset.take(num_records):\n",
    "        \n",
    "        # Get the numpy property of the tensor\n",
    "        serialized_example = tfrecord.numpy()\n",
    "        \n",
    "        # Initialize a `tf.train.Example()` to read the serialized data\n",
    "        example = tf.train.Example()\n",
    "        \n",
    "        # Read the example data (output is a protocol buffer message)\n",
    "        example.ParseFromString(serialized_example)\n",
    "        \n",
    "        # convert the protocol bufffer message to a Python dictionary\n",
    "        example_dict = (MessageToDict(example))\n",
    "        \n",
    "        # append to the records list\n",
    "        records.append(example_dict)\n",
    "        \n",
    "    return records\n",
    "\n",
    "def display_types(types):\n",
    "    # Helper function to render dataframes for the artifact and execution types\n",
    "    table = {'id': [], 'name': []}\n",
    "    for a_type in types:\n",
    "        table['id'].append(a_type.id)\n",
    "        table['name'].append(a_type.name)\n",
    "    return pd.DataFrame(data=table)\n",
    "\n",
    "def display_artifacts(store, artifacts, base_dir):\n",
    "    # Helper function to render dataframes for the input artifacts\n",
    "    table = {'artifact id': [], 'type': [], 'uri': []}\n",
    "    for a in artifacts:\n",
    "        table['artifact id'].append(a.id)\n",
    "        artifact_type = store.get_artifact_types_by_id([a.type_id])[0]\n",
    "        table['type'].append(artifact_type.name)\n",
    "        table['uri'].append(a.uri.replace(base_dir, './'))\n",
    "    return pd.DataFrame(data=table)\n",
    "\n",
    "def display_properties(store, node):\n",
    "    # Helper function to render dataframes for artifact and execution properties\n",
    "    table = {'property': [], 'value': []}\n",
    "    \n",
    "    for k, v in node.properties.items():\n",
    "        table['property'].append(k)\n",
    "        table['value'].append(\n",
    "            v.string_value if v.HasField('string_value') else v.int_value)\n",
    "    \n",
    "    for k, v in node.custom_properties.items():\n",
    "        table['property'].append(k)\n",
    "        table['value'].append(\n",
    "            v.string_value if v.HasField('string_value') else v.int_value)\n",
    "    \n",
    "    return pd.DataFrame(data=table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_metadata as mlmd\n",
    "from ml_metadata.metadata_store import metadata_store\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "\n",
    "connection_config = metadata_store_pb2.ConnectionConfig()\n",
    "connection_config.sqlite.filename_uri = 'pipeline/metadata.sqlite'\n",
    "connection_config.sqlite.connection_mode = 3 # READWRITE_OPENCREATE\n",
    "store = metadata_store.MetadataStore(connection_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Acceso a artefactos almacenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo tomado de https://www.tensorflow.org/tfx/guide/mlmd\n",
    "artifact_types = store.get_artifact_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_types(artifact_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Seguimiento de artefactos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Obtener artefactos principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_transform = store.get_artifacts_by_type('TransformGraph')\n",
    "_id = artifact_transform[0].id\n",
    "artifacts_p = get_main_artifacts(store, _id)\n",
    "get_records( display_artifacts(store, artifacts_p, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyO6xkVlvkY293KX+hADNxfD",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
